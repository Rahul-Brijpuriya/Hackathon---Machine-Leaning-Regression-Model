# Amazon Delivery Time Prediction System

## ğŸ“– Project Overview
This project is an end-to-end Machine Learning pipeline designed to predict the **estimated time of delivery** for Amazon orders based on various logistical factors. Unlike simple estimation methods, this system utilizes advanced regression models to analyze historical dataâ€”such as delivery person age, ratings, location coordinates, traffic density, and weather conditionsâ€”to forecast precise delivery times.

The project follows a standard ML lifecycle: **Data Ingestion â†’ Preprocessing â†’ Model Training â†’ Evaluation â†’ Deployment**.

## ğŸ“Š Workflow Architecture
1. **Data Ingestion:** Loads the `Amazon_delivery_time.csv` dataset containing delivery logs.
2. **Preprocessing:** - **Handling Missing Values:** Imputation strategies for null values.
   - **Feature Engineering:** Calculating the distance between the restaurant and delivery location using the Haversine formula.
   - **Encoding:** One-Hot Encoding for categorical data (e.g., Weather, Traffic).
   - **Scaling:** Standardizing numerical features using Scikit-Learn Pipelines.
3. **Modeling:**
   - **Linear Regression:** Baseline model to establish linear relationships.
   - **Ridge Regression:** Regularized linear model to handle multicollinearity.
   - **Random Forest Regressor:** Bagging ensemble method to handle non-linear data and reduce variance.
   - **XGBoost Regressor:** Boosting ensemble method that provided the highest accuracy.
4. **Deployment:** A web-based user interface built with **Streamlit** that takes delivery parameters and predicts the time in minutes.

## ğŸ“ˆ Model Evaluation
The models were trained and evaluated on the industrial dataset. Below is the performance comparison across all trained models, sorted by performance:

| Metric | Linear Regression | Ridge Regression | Random Forest | XGBoost Regressor |
| :--- | :--- | :--- | :--- | :--- |
| **RMSE** (Root Mean Squared Error) | 33.3036 | 33.3042 | 23.1124 | **22.1654** |
| **MAE** (Mean Absolute Error) | 26.3118 | 26.3116 | 17.6397 | **17.1974** |
| **RÂ² Score** | 0.5782 | 0.5782 | 0.7969 | **0.8132** |
| **Adjusted RÂ²** | 0.5779 | 0.5778 | 0.7967 | **0.8130** |
| **MAPE** (Mean Absolute Percentage Error) | 27.96% | 27.96% | 16.16% | **15.94%** |

> **Key Observation:** > * **Tree-based models (XGBoost & Random Forest) significantly outperform** the linear models, explaining ~80-81% of the variance compared to ~58% for linear models. 
> * **XGBoost** is the best-performing model with the lowest RMSE (22.16) and highest RÂ² (0.8132).

## ğŸ› ï¸ Tech Stack
* **Language:** Python
* **Data Manipulation:** Pandas, NumPy
* **Machine Learning:** Scikit-Learn (Linear, Ridge, Random Forest), XGBoost
* **Web Interface:** Streamlit
* **Utils:** Pickle (for model serialization)

## ğŸ“‚ Project Structure
```text
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Amazon_delivery_time.csv      # Raw Dataset
â”œâ”€â”€ models/
â”‚   â””â”€â”€ final_model.pkl               # Saved Best Model (XGBoost)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ logger.py                     # Logging configuration
â”‚   â”œâ”€â”€ exception.py                  # Custom exception handling
â”‚   â””â”€â”€ utils.py                      # Utility functions
â”œâ”€â”€ train_model.py                    # Script to preprocess, train, and save model
â”œâ”€â”€ app.py                            # Streamlit frontend application
â”œâ”€â”€ requirements.txt                  # List of dependencies
â””â”€â”€ README.md                         # Project documentation
